---
title: "R Notebook"
output: html_notebook
---
## Problem 2: Sums of Squares

a. Using for loop
```{r}
# Generate the data
set.seed(12345)
y <- seq(from = 1, to = 100, length.out = 1e+08) + rnorm(1e+08)

# Create for loop to calculate Syy
loop_time <- system.time({
  Syy <- 0
  mean_y <- mean(y)

  for (i in 1:length(y)) {
    Syy <- Syy + (y[i]-mean_y)^2    
  }
})
```

b. Use vector operations

```{r}
vect_time <- system.time({
  diffSq <- (y-mean_y)^2
  Syy <- sum(diffSq)
})

# report the result
report1 <- data.frame(Method = c("Loop","Vector Ops"), User =c(loop_time[1],vect_time[1]), System =c(loop_time[2],vect_time[2]), Elapsed =c(loop_time[3],vect_time[3]))

knitr::kable(report1,caption="Running time comparison table")
```

Using vector operations is a lot faster than using a for loop.

## Problem 3: Using the dual nature to our advantage

```{r}
set.seed(1256)
theta <- as.matrix(c(1, 2), nrow = 2)
X <- cbind(1, rep(1:10, 10))
h <- X %*% theta + rnorm(100, 0, 0.2)

tolerance <- as.matrix(c(1e-5,1e-5),nrow=2)
alpha <- 0.01 #Step size
m <- nrow(h)
  
# old_theta hold values of theta from last iteration
old_theta <- as.matrix(c(10,10),nrow=2) # an arbitray value to start the loop

# new_theta hold values of theta calculating from the data and old theta 
new_theta <- as.matrix(c(8,8),nrow=2)

counter <- 0
while(sum(abs(new_theta - old_theta) > tolerance) == 2) {
  old_theta <- new_theta
  
  h0x <- old_theta[1,] + old_theta[2,]*X[,2]
  
  new_theta[1,] <- old_theta[1,] - alpha/m*sum(h0x-h[,1])
  
  new_theta[2,] <- old_theta[2,] - alpha/m*sum((h0x-h[,1])*X[,2])
  
  counter <- counter + 1

}

#Get least square estimations of coefficent
lmfit <- lm(h~0+X)

#Build a comparison table
result3 <- data.frame(Method = c("Our Method","LSE"), Beta_0 = c(new_theta[1,],lmfit$coefficients[1]),Beta_1 = c(new_theta[2,],lmfit$coefficients[2]))

knitr::kable(result3,caption="Coefficient Estimates Comparison Between 2 methods")

```

## Problem 4: Inverting matrices

Finding $\hat{\beta}$ by computing $(X'X)^{-1}X'\underline{y}$ will be a computationally expensive operation since it involves a matrix multiplication followed by an invert and another 2 matrix multiplications. If $n$, the number of observations, is a very large number, chances are we will use up a lot of memory to find just a 2x1 matrix of $\hat{\beta}$.

In this case, I will rely on the numerical solution for $\hat{\beta}$ and calculate $\hat{\beta_0}$ and $\hat{\beta_1}$ separately using vector operations.

## Problem 5: Need for speed

```{r}
set.seed(12456)
G <- matrix(sample(c(0, 0.5, 1), size = 16000, replace = T),
ncol = 10)
R <- cor(G) # R: 10 * 10 correlation matrix of G
C <- kronecker(R, diag(1600)) # C is a 16000 * 16000 block diagonal matrix
id <- sample(1:16000, size = 932, replace = F)
q <- sample(c(0, 0.5, 1), size = 15068, replace = T) # vector of length 15068
A <- C[id, -id] # matrix of dimension 932 * 15068
B <- C[-id, -id] # matrix of dimension 15068 * 15068
p <- runif(932, 0, 1)
r <- runif(15068, 0, 1)
C <- NULL #save some memory space
```

a. Size of A and B
```{r}
# Size of object A:
object.size(A)

# Size of object B:
object.size(B)
```

Calculating $y = p + AB^{-1}(q-r)$ consists of several vector and matrix addition, one matrix inversion, and two matrix multiplications. The first operation is vector subtraction $q-r$. Complexity for this operation is linear, which means equal the size of the vector, 15068. Next, matrix inversion takes up complexity of $O(n^3)$, which in this case is $15068^3$. Then, matrix multiplcation between $A_{n\times m}$ and $B^{-1}_{m \times p}$ takes up $O(mnp)$. Specifically, it will take $932 \times 15068^2$ in our case. Next, matrix multiplication between $AB^{-1}$ and $(q-r)$ takes up $932\times15068$. Finally, vector addition between $p$ and $AB^{-1}(q-r)$ takes up linear time, which is $932$ operations. 

All in all, it will take $15068 + 15068^3 + 932\times15068^2+932\times15068 + 932$ operations to compute $y$.

b. Optimization

Recognizing that matrix B already consists of a diagonal of $1$'s and because of the nature of subsetting from a kronecker matrix coming from a matrix and identity matrix, most of the values in B will consist of 0's. Thus, instead of using the "solve" function, we can program our own function to invert matrices by using a parralel Identity matrix as inspired by the Gauss-Jordan elimination. By using vector addition and scalar multiplication, we hope to reduce the run time instead of going through the "solve" function.

```{r}
op.time <- system.time({

invert_matrix <- function(M) {
  I <- diag(nrow(M))
  # Upper triangular transformation
  
  # Going through each column c in M (starting from 1) and
  # look at the values on row greater than c, if they are nonzero
  # then perform transformation. If the value is on row z,
  # then use row z of M as the pivot
  for (c in 1:ncol(M)) {
    
    # Check if M[c,c] = 1. If not, divide the whole row by M[c,c]
    if (M[c,c] != 1) {
      I[c,] <- I[c,]/M[c,c]
      M[c,] <- M[c,]/M[c,c]
    }
    
    #Get the row with values other than 0 exclude rows less or equal to c
    notZero <- which(M[,c] != 0)
    notZero <- notZero[notZero > c]
    
    # For every row z indicated in notZero, take the row z of I and subtract it by row c of I multiplied by the nonzero value
    for (z in notZero) {
      I[z,] <- I[z,] - M[z,c] * I[c,]
      M[z,] <- M[z,] - M[z,c] * M[c,]
    }
  }    
   
  #Check for 1's diagonal
  not1 <- which(diag(M) != 1)
  for (i in not1) {
    #Divide that row by that value
    if (M[i,i] != 0) {
      I[i,] <- I[i,]/M[i,i]
      M[i,] <- M[i,]/M[i,i]
    }
  }
    
  # Lower triangular transformation
  for (r in 1:nrow(M)) {
    
    # Get the column with values other than 0 (excluding column r)
    notZero <- which(M[r,] != 0)
    notZero <- notZero[notZero!=r]
    
    # For every column z indicated in notZero, take row r of I and subtract it by row z of I multiplied by the nonzero value
    for (z in notZero) {
      I[r,] <- I[r,] - I[z,]*M[r,z]
      M[r,] <- M[r,] - M[z,]*M[r,z]
    }
  }
  print("Done with inverting")
  return (I)
}

#Multiplying A and B_invert
# Since each row i of A and columns of B contain a lot of zeros,
# non-zero dot product only occur when there exist positions within # the row and column where the values are non-zero

## Initialize an empty result matrix

mat.mat.mult <- function (A,inv_B) {
  A.invB <- matrix(0L,nrow=nrow(A),ncol=ncol(inv_B))

for (i in 1:nrow(A)) {
  # If the current row contains only 0's, skip to next row
  if (all(A[i,] == rep(0,ncol(A))))
    {
      next
    }
  
  for (j in 1:ncol(inv_B)) {
    if (all(inv_B[,j] == rep(0,nrow(inv_B)))) {
      next
    }
    # Obtain the position where nonzero element exists
    notZero_A <- which(A[i,] != 0)
    notZero_invB <- which(inv_B[,j] != 0)
    
    #Find the common position of nonzero between A's row i and B's col j
    both_nonZero <- intersect(notZero_A,notZero_invB)
    
    #If exists, then perform dot product and assign to A.invB[i,j]
    if (length(both_nonZero) > 0) {
      A.invB[i,j] <- A[i,both_nonZero] %*% inv_B[both_nonZero,j]
    }
  }
}
  print("Done with multiplying mat mat")
 return (A.invB) 
}

# Calculate A*inv(B)*(q-r)

mat.vect.mult <- function(A.invB,q.subr.r) {
  result <- rep(0,nrow(A))

for (i in 1:nrow(A.invB)) {
  if (all(A.invB[i,] == rep(0,ncol(A.invB)))){
    next
  } 
  
  #Apply the same scheme, only rows containing non-zero values matter
  nonZero_posit <- which(A.invB[i,] != 0)
  result[i] <- A.invB[i,nonZero_posit] %*% q.subr.r[nonZero_posit]
}
  print("Done with multiplying mat vect")
  return(result)
}

my_Y <- p + mat.vect.mult(mat.mat.mult(A,invert_matrix(B)),q-r)

})

```

c. Put everything to test

```{r}
# Non-optimization way
non.op.time <- system.time(
  {
    true_Y <- p + A%*%solve(B)%*%(q-r)
  }
)

#Check result
plot(true_Y,my_Y,pch=16)

# Comparison
report5 <- data.frame(Method = c("Non optimization","Optimization"), User =c(non.op.time[1],op.time[1]), System =c(non.op.time[2],op.time[2]), Elapsed =c(non.op.time[3],op.time[3]))

knitr::kable(report5,caption="Running time comparison table")

```



## How to use R Notebook
Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
